{"version":3,"sources":["model.ts"],"names":["debug","DEBUG","sub","hash","str","crypto","createHash","update","digest","_cacheDumpDisabled","_vectorsCachePath","path","join","process","APP_DATA_PATH","_vectorsCache","lru","length","arr","BYTES_PER_ELEMENT","Float32Array","max","onVectorsCacheChanged","dumpVectorsCache","fse","ensureFile","writeJSON","dump","err","message","restoreVectorsCache","pathExists","readJSON","kve","map","x","e","k","v","from","Object","values","load","restoreCachePromise","ENDPOINT","env","BP_MODULE_KB_ENDPOINT","getCacheKey","lang","input","toLowerCase","trim","RemoteModel","constructor","entries","langs","trained","model","getPhraseVector","phrase","cacheKey","has","Array","get","data","axios","post","documents","embeddings","isNaN","Error","set","console","log","train","training","cancelled","_","uniq","flatten","keys","content","title","progress","i","total","percent","toFixed","support_vectors","trained_on","Date","entry","questions","feedback","filter","polarity","utterance","title_embedding","originalContentEmb","reranked_emb","question","questionEmb","questionEmbNorm","direction","push","content_embedding","cancelTraining","compute_confidence","question_embed","conf_content","similarity","cosine","conf_title","confidence","predict","langCode","sv","top","chain","orderBy","take","value","docs","score","toJSON","JSON","stringify","fromJSON","parse"],"mappings":";;;;;;;AAAA;;AAEA;;AACA;;AAEA;;AACA;;AACA;;AACA;;AACA;;AACA;;AAEA;;;;;;;;;;AAGA,MAAMA,KAAK,GAAGC,KAAK,CAAC,IAAD,CAAL,CAAYC,GAAZ,CAAgB,MAAhB,CAAd;;AAEA,MAAMC,IAAI,GAAGC,GAAG,IACdC,gBACGC,UADH,CACc,KADd,EAEGC,MAFH,CAEUH,GAFV,EAGGI,MAHH,CAGU,KAHV,CADF;;AAMA,IAAIC,kBAAkB,GAAG,KAAzB;;AAEA,MAAMC,iBAAiB,GAAGC,cAAKC,IAAL,CAAUC,OAAO,CAACC,aAAlB,EAAiC,OAAjC,EAA0C,qBAA1C,CAA1B;;AACA,MAAMC,aAAwC,GAAG,IAAIC,iBAAJ,CAA8B;AAC7EC,EAAAA,MAAM,EAAGC,GAAD,IAAuB;AAC7B,QAAIA,GAAG,IAAIA,GAAG,CAACC,iBAAf,EAAkC;AAChC,aAAOD,GAAG,CAACD,MAAJ,GAAaC,GAAG,CAACC,iBAAxB;AACD,KAFD,MAEO;AACL,aAAO;AAAI;AAAJ,QAAgBC,YAAY,CAACD,iBAApC;AACD;AACF,GAP4E;AAQ7EE,EAAAA,GAAG,EAAE;AAAI;AAAJ,IAAgBD,YAAY,CAACD;AAAkB;AAA/C,IAA6D;AAAS;;AARE,CAA9B,CAAjD;;AAWA,MAAMG,qBAAqB,GAAG,sBAAS,YAAY;AACjD,MAAI,CAACb,kBAAL,EAAyB;AACvB,UAAMc,gBAAgB,EAAtB;AACD;AACF,CAJ6B,EAI3B,iBAAG,IAAH,CAJ2B,CAA9B;;AAMA,eAAeA,gBAAf,GAAkC;AAChC,MAAI;AACF,UAAMC,iBAAIC,UAAJ,CAAef,iBAAf,CAAN;AACA,UAAMc,iBAAIE,SAAJ,CAAchB,iBAAd,EAAiCK,aAAa,CAACY,IAAd,EAAjC,CAAN;AACA3B,IAAAA,KAAK,CAAC,8BAAD,EAAiCU,iBAAjC,CAAL;AACD,GAJD,CAIE,OAAOkB,GAAP,EAAY;AACZnB,IAAAA,kBAAkB,GAAG,IAArB;AACAT,IAAAA,KAAK,CAAC,4CAAD,EAA+C4B,GAAG,CAACC,OAAnD,CAAL;AACD;AACF;;AAED,eAAeC,mBAAf,GAAqC;AACnC,MAAI;AACF,QAAI,MAAMN,iBAAIO,UAAJ,CAAerB,iBAAf,CAAV,EAA6C;AAC3C,YAAMiB,IAAI,GAAG,MAAMH,iBAAIQ,QAAJ,CAAatB,iBAAb,CAAnB;;AACA,UAAIiB,IAAJ,EAAU;AACR,cAAMM,GAAG,GAAGN,IAAI,CAACO,GAAL,CAASC,CAAC,KAAK;AAAEC,UAAAA,CAAC,EAAED,CAAC,CAACC,CAAP;AAAUC,UAAAA,CAAC,EAAEF,CAAC,CAACE,CAAf;AAAkBC,UAAAA,CAAC,EAAElB,YAAY,CAACmB,IAAb,CAAkBC,MAAM,CAACC,MAAP,CAAcN,CAAC,CAACG,CAAhB,CAAlB;AAArB,SAAL,CAAV,CAAZ;;AACAvB,QAAAA,aAAa,CAAC2B,IAAd,CAAmBT,GAAnB;AACD;AACF;AACF,GARD,CAQE,OAAOL,GAAP,EAAY;AACZ5B,IAAAA,KAAK,CAAC,4CAAD,EAA+C4B,GAAG,CAACC,OAAnD,CAAL;AACD;AACF;;AAED,MAAMc,mBAAmB,GAAGb,mBAAmB,EAA/C;AAEA,MAAMc,QAAQ,GAAG/B,OAAO,CAACgC,GAAR,CAAYC,qBAAZ,IAAqC,qCAAtD;;AACA,MAAMC,WAAW,GAAG,CAACC,IAAD,EAAeC,KAAf,KACjB,GAAE9C,IAAI,CAAC,2BAAa8C,KAAb,CAAD,CAAJ,CACAC,WADA,GAEAC,IAFA,EAEO,KAAIH,IAAI,CAACE,WAAL,GAAmBC,IAAnB,EAA0B,EAH1C;;AAKe,MAAMC,WAAN,CAAmC;AAIhDC,EAAAA,WAAW,CACDC,OAAgB,GAAG,EADlB,EAEDC,KAAe,GAAG,EAFjB,EAGDC,OAAgB,GAAG,KAHlB,EAIDC,KAJC,EAKT;AAAA,SAJQH,OAIR,GAJQA,OAIR;AAAA,SAHQC,KAGR,GAHQA,KAGR;AAAA,SAFQC,OAER,GAFQA,OAER;AAAA,SADQC,KACR,GADQA,KACR;;AAAA,sCARiB,KAQjB;;AAAA,uCAPkB,KAOlB;AAAE;;AAEJ,QAAcC,eAAd,CAA8BC,MAA9B,EAA8CX,IAA9C,EAA2F;AACzF,QAAI;AACF,YAAMY,QAAQ,GAAGb,WAAW,CAACC,IAAD,EAAOW,MAAP,CAA5B;;AAEA,UAAI5C,aAAa,CAAC8C,GAAd,CAAkBD,QAAlB,CAAJ,EAAiC;AAC/B,eAAOE,KAAK,CAACvB,IAAN,CAAWxB,aAAa,CAACgD,GAAd,CAAkBH,QAAlB,EAA4BnB,MAA5B,EAAX,CAAP;AACD;;AAED,YAAM;AAAEuB,QAAAA;AAAF,UAAW,MAAMC,eAAMC,IAAN,CAAWtB,QAAQ,GAAG,aAAtB,EAAqC;AAC1DI,QAAAA,IAAI,EAAEA,IAAI,CAACE,WAAL,GAAmBC,IAAnB,EADoD;AAE1DgB,QAAAA,SAAS,EAAE,CAAC,2BAAaR,MAAb,CAAD;AAF+C,OAArC,CAAvB,CAPE,CAWF;AACA;;AAEA,YAAMS,UAAU,GAAGJ,IAAI,CAACA,IAAL,CAAU,CAAV,CAAnB;;AACA,UAAI,CAACI,UAAD,IAAe,CAACA,UAAU,CAACnD,MAA3B,IAAqCoD,KAAK,CAACD,UAAU,CAAC,CAAD,CAAX,CAA9C,EAA+D;AAC7D,cAAM,IAAIE,KAAJ,CAAU,6BAAV,CAAN;AACD;;AAEDvD,MAAAA,aAAa,CAACwD,GAAd,CAAkBxB,WAAW,CAACC,IAAD,EAAOW,MAAP,CAA7B,EAA6CS,UAA7C;;AACA9C,MAAAA,qBAAqB,GApBnB,CAoBsB;;AACxB,aAAO8C,UAAP;AACD,KAtBD,CAsBE,OAAOxC,GAAP,EAAY;AACZ4C,MAAAA,OAAO,CAACC,GAAR,CAAY7C,GAAZ;AACD;AACF;;AAED,QAAM8C,KAAN,CAAYV,IAAZ,EAA6C;AAC3C,QAAI,KAAKW,QAAT,EAAmB;AACjB,YAAM,IAAIL,KAAJ,CAAU,kBAAV,CAAN;AACD;;AAED,QAAI,KAAKd,OAAT,EAAkB;AAChB,YAAM,IAAIc,KAAJ,CAAU,iBAAV,CAAN;AACD;;AAED,UAAM3B,mBAAN,CAT2C,CASjB;;AAE1B,SAAKa,OAAL,GAAe,KAAf;AACA,SAAKoB,SAAL,GAAiB,KAAjB;AACA,SAAKD,QAAL,GAAgB,IAAhB;;AAEA,QAAI;AACF,YAAMpB,KAAK,GAAGsB,gBAAEC,IAAF,CAAOD,gBAAEE,OAAF,CAAUf,IAAI,CAAC9B,GAAL,CAASC,CAAC,IAAI,CAAC,GAAGK,MAAM,CAACwC,IAAP,CAAY7C,CAAC,CAAC8C,OAAd,CAAJ,EAA4B,GAAGzC,MAAM,CAACwC,IAAP,CAAY7C,CAAC,CAAC+C,KAAd,CAA/B,CAAd,CAAV,CAAP,CAAd;;AACA,YAAM;AAAEC,QAAAA;AAAF,UAAgB,YAAW;AAC/B,YAAIC,CAAC,GAAG,CAAR;AACA,cAAMC,KAAK,GAAGrB,IAAI,CAAC/C,MAAnB;;AACA,cAAMkE,QAAQ,GAAG,MAAM;AACrB,gBAAMG,OAAO,GAAG,CAAEF,CAAC,KAAKC,KAAP,GAAgB,GAAjB,EAAsBE,OAAtB,CAA8B,CAA9B,CAAhB;AACAvF,UAAAA,KAAK,CAAE,eAAcoF,CAAE,MAAKC,KAAM,KAAIC,OAAQ,KAAzC,CAAL;AACD,SAHD;;AAIA,eAAO;AAAEH,UAAAA;AAAF,SAAP;AACD,OARoB,EAArB;;AAUA,YAAM1B,KAAmB,GAAG;AAAEH,QAAAA,OAAO,EAAE,CAAC,GAAGU,IAAJ,CAAX;AAAsBwB,QAAAA,eAAe,EAAE,EAAvC;AAA2CC,QAAAA,UAAU,EAAE,IAAIC,IAAJ;AAAvD,OAA5B;;AAEA,WAAK,MAAMC,KAAX,IAAoB3B,IAApB,EAA0B;AACxB,YAAI,KAAKY,SAAT,EAAoB;AAClB;AACD;;AACD,aAAK,MAAM5B,IAAX,IAAmBO,KAAnB,EAA0B;AACxB,cAAI,KAAKqB,SAAT,EAAoB;AAClB;AACD;;AAED,gBAAMgB,SAAS,GAAGf,gBAAEC,IAAF,CAAO,CACvBa,KAAK,CAACT,KAAN,CAAYlC,IAAZ,CADuB,EAEvB,GAAG2C,KAAK,CAACE,QAAN,CAAe7C,IAAf,EAAqB8C,MAArB,CAA4B3D,CAAC,IAAIA,CAAC,CAAC4D,QAAnC,EAA6C7D,GAA7C,CAAiDC,CAAC,IAAIA,CAAC,CAAC6D,SAAxD,CAFoB,CAAP,CAAlB,CALwB,CAUxB;;;AACA,gBAAMd,KAAK,GAAGS,KAAK,CAACT,KAAN,CAAYlC,IAAZ,CAAd;AACA,gBAAMiD,eAAe,GAAG,MAAM,KAAKvC,eAAL,CAAqBwB,KAArB,EAA4BlC,IAA5B,CAA9B;;AAEA,eAAK,MAAMiC,OAAX,IAAsBU,KAAK,CAACV,OAAN,CAAcjC,IAAd,CAAtB,EAA2C;AACzC,kBAAMkD,kBAAkB,GAAG,MAAM,KAAKxC,eAAL,CAAqBuB,OAArB,EAA8BjC,IAA9B,CAAjC;;AACA,gBAAI,CAACkD,kBAAL,EAAyB;AACvB;AACD;;AACD,gBAAIC,YAAY,GAAG,CAAC,GAAGD,kBAAJ,CAAnB;;AACA,iBAAK,MAAME,QAAX,IAAuBR,SAAvB,EAAkC;AAChC,oBAAMS,WAAW,GAAG,MAAM,KAAK3C,eAAL,CAAqB0C,QAArB,EAA+BpD,IAA/B,CAA1B;;AACA,kBAAI,CAACqD,WAAL,EAAkB;AAChB;AACD;;AACD,oBAAMC,eAAe,GAAG,sBAAS,kBAAKH,YAAL,IAAqB,kBAAKE,WAAL,CAA9B,EAAiD,CAAC,GAAGA,WAAJ,CAAjD,CAAxB;AACA,oBAAME,SAAS,GAAG,sBAASD,eAAT,EAA0BH,YAA1B,CAAlB;AACAA,cAAAA,YAAY,GAAG,iBAAIA,YAAJ,EAAkB,sBAAS,GAAT,EAAcI,SAAd,CAAlB,CAAf;;AACAxF,cAAAA,aAAa,CAACwD,GAAd,CAAkBxB,WAAW,CAACC,IAAD,EAAOiC,OAAP,CAA7B,EAA8C7D,YAAY,CAACmB,IAAb,CAAkB4D,YAAlB,CAA9C;AACD,aAfwC,CAiBzC;;;AACA1C,YAAAA,KAAK,CAAC+B,eAAN,CAAsBgB,IAAtB,CAA2B;AACzBC,cAAAA,iBAAiB,EAAEN,YADM;AAEzBF,cAAAA,eAFyB;AAGzBjD,cAAAA,IAHyB;AAIzBiC,cAAAA,OAJyB;AAKzBC,cAAAA;AALyB,aAA3B,EAlByC,CAyBzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACD;AACF;;AAEDC,QAAAA,QAAQ;AACT;;AAED,UAAI,CAAC,KAAKP,SAAV,EAAqB;AACnB,aAAKtB,OAAL,GAAeU,IAAf;AACA,aAAKT,KAAL,GAAaA,KAAb;AACA,aAAKC,OAAL,GAAe,IAAf;AACA,aAAKC,KAAL,GAAaA,KAAb;AACD;AACF,KA9ED,CA8EE,OAAO7B,GAAP,EAAY;AACZ,WAAK4B,OAAL,GAAe,KAAf;AACAxD,MAAAA,KAAK,CAAC,mBAAD,EAAsB4B,GAAtB,CAAL;AACD,KAjFD,SAiFU;AACR,WAAK+C,QAAL,GAAgB,KAAhB;AACA,WAAKC,SAAL,GAAiB,KAAjB;AACA,aAAO,KAAKpB,OAAZ;AACD;AACF;;AAEDkD,EAAAA,cAAc,GAAS;AACrB,QAAI,CAAC,KAAK/B,QAAV,EAAoB;AAClB,YAAM,IAAIL,KAAJ,CAAU,wDAAV,CAAN;AACD;;AAED,SAAKM,SAAL,GAAiB,IAAjB;AACD,GApJ+C,CAsJhD;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA+B,EAAAA,kBAAkB,CAACnB,eAAD,EAAiCoB,cAAjC,EAAiD;AACjE,UAAMC,YAAY,GAAGC,uBAAWC,MAAX,CAAkBvB,eAAe,CAACiB,iBAAlC,EAAqDG,cAArD,CAArB;;AACA,UAAMI,UAAU,GAAGF,uBAAWC,MAAX,CAAkBvB,eAAe,CAACS,eAAlC,EAAmDW,cAAnD,CAAnB;;AACA,UAAMK,UAAU,GAAG,CAACD,UAAU,GAAGH,YAAd,IAA8B,CAAjD,CAHiE,CAKjE;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,WAAOI,UAAP;AACD;;AAED,QAAMC,OAAN,CAAcjE,KAAd,EAA6BkE,QAA7B,EAA6D;AAC3D,QAAI,CAAC,KAAK3D,OAAV,EAAmB;AACjB,YAAM,IAAIc,KAAJ,CAAU,4CAAV,CAAN;AACD;;AAED,QAAI,KAAKK,QAAT,EAAmB;AACjB,YAAM,IAAIL,KAAJ,CAAU,mDAAV,CAAN;AACD;;AAED6C,IAAAA,QAAQ,GAAGA,QAAQ,CAACjE,WAAT,GAAuBC,IAAvB,EAAX;AAEA,UAAMyD,cAAc,GAAG,MAAM,KAAKlD,eAAL,CAAqBT,KAArB,EAA4BkE,QAA5B,CAA7B;AAEA,UAAMC,EAAE,GAAG,KAAK3D,KAAL,CAAW+B,eAAX,CACRM,MADQ,CACD3D,CAAC,IAAIA,CAAC,CAACa,IAAF,KAAWmE,QADf,EAERjF,GAFQ,CAEJkF,EAAE,KAAK,EACV,GAAGA,EADO;AAEVH,MAAAA,UAAU,EAAE,KAAKN,kBAAL,CAAwBS,EAAxB,EAA4BR,cAA5B;AAFF,KAAL,CAFE,CAAX;;AAOA,UAAMS,GAAU,GAAGxC,gBAAEyC,KAAF,CAAQF,EAAR,EAChBtB,MADgB,CACT3D,CAAC,IAAI,CAACkC,KAAK,CAAClC,CAAC,CAAC8E,UAAH,CAAN,IAAwB9E,CAAC,CAAC8E,UAAF,GAAe,CADnC,EAEhBM,OAFgB,CAER,YAFQ,EAEM,MAFN,EAGhBC,IAHgB,CAGX,CAHW,EAIhBC,KAJgB,EAAnB,CApB2D,CA0B3D;AACA;AACA;AACA;AACA;AACA;AACA;;;AAEA,WAAO;AACLC,MAAAA,IAAI,EAAE,CACJ;AAAEzC,QAAAA,OAAO,EAAEoC,GAAG,CAAC,CAAD,CAAH,CAAOpC,OAAlB;AAA2B0C,QAAAA,KAAK,EAAEN,GAAG,CAAC,CAAD,CAAH,CAAOJ;AAAzC,OADI,EAEJ;AAAEhC,QAAAA,OAAO,EAAEoC,GAAG,CAAC,CAAD,CAAH,CAAOpC,OAAlB;AAA2B0C,QAAAA,KAAK,EAAEN,GAAG,CAAC,CAAD,CAAH,CAAOJ;AAAzC,OAFI,EAGJ;AAAEhC,QAAAA,OAAO,EAAEoC,GAAG,CAAC,CAAD,CAAH,CAAOpC,OAAlB;AAA2B0C,QAAAA,KAAK,EAAEN,GAAG,CAAC,CAAD,CAAH,CAAOJ;AAAzC,OAHI,CADD,CAML;;AANK,KAAP,CAlC2D,CA0C3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACD;;AAEDW,EAAAA,MAAM,GAAW;AACf,QAAI,CAAC,KAAKpE,OAAV,EAAmB;AACjB,YAAM,IAAIc,KAAJ,CAAU,oDAAV,CAAN;AACD;;AAED,QAAI,KAAKK,QAAT,EAAmB;AACjB,YAAM,IAAIL,KAAJ,CAAU,2DAAV,CAAN;AACD;;AAED,WAAOuD,IAAI,CAACC,SAAL,CAAe;AACpBtE,MAAAA,OAAO,EAAE,KAAKA,OADM;AAEpBF,MAAAA,OAAO,EAAE,KAAKA,OAFM;AAGpBG,MAAAA,KAAK,EAAE,KAAKA,KAHQ;AAIpBF,MAAAA,KAAK,EAAE,KAAKA;AAJQ,KAAf,CAAP;AAMD;;AAED,eAAawE,QAAb,CAAsB/D,IAAtB,EAA0D;AACxD,UAAM;AAAEP,MAAAA,KAAF;AAASF,MAAAA,KAAT;AAAgBD,MAAAA,OAAhB;AAAyBE,MAAAA;AAAzB,QAAqCqE,IAAI,CAACG,KAAL,CAAWhE,IAAX,CAA3C;AACA,WAAO,IAAIZ,WAAJ,CAAgBE,OAAhB,EAAyBC,KAAzB,EAAgCC,OAAhC,EAAyCC,KAAzC,CAAP;AACD;;AA7V+C","sourceRoot":"/mnt/Documents/Projets/BotPress/botpress/modules/kb/src/backend","sourcesContent":["import axios, { AxiosInstance } from 'axios'\nimport retry from 'bluebird-retry'\nimport crypto from 'crypto'\nimport fse from 'fs-extra'\nimport httpsProxyAgent from 'https-proxy-agent'\nimport _, { debounce, sumBy } from 'lodash'\nimport lru from 'lru-cache'\nimport { add, divide, multiply, norm, subtract } from 'mathjs'\nimport { distance, similarity } from 'ml-distance'\nimport ms from 'ms'\nimport path from 'path'\n\nimport { sanitizeText } from './storage'\nimport { Entry, Model, Prediction, SupportVector, TrainedModel } from './typings'\n\nconst debug = DEBUG('kb').sub('lang')\n\nconst hash = str =>\n  crypto\n    .createHash('md5')\n    .update(str)\n    .digest('hex')\n\nlet _cacheDumpDisabled = false\n\nconst _vectorsCachePath = path.join(process.APP_DATA_PATH, 'cache', 'mod_kb_vectors.json')\nconst _vectorsCache: lru<string, Float32Array> = new lru<string, Float32Array>({\n  length: (arr: Float32Array) => {\n    if (arr && arr.BYTES_PER_ELEMENT) {\n      return arr.length * arr.BYTES_PER_ELEMENT\n    } else {\n      return 768 /* dim */ * Float32Array.BYTES_PER_ELEMENT\n    }\n  },\n  max: 768 /* dim */ * Float32Array.BYTES_PER_ELEMENT /* bytes */ * 10000000 /* 10M sentences */\n})\n\nconst onVectorsCacheChanged = debounce(async () => {\n  if (!_cacheDumpDisabled) {\n    await dumpVectorsCache()\n  }\n}, ms('5s'))\n\nasync function dumpVectorsCache() {\n  try {\n    await fse.ensureFile(_vectorsCachePath)\n    await fse.writeJSON(_vectorsCachePath, _vectorsCache.dump())\n    debug('vectors cache updated at: %s', _vectorsCachePath)\n  } catch (err) {\n    _cacheDumpDisabled = true\n    debug('could not persist vectors cache, error: %s', err.message)\n  }\n}\n\nasync function restoreVectorsCache() {\n  try {\n    if (await fse.pathExists(_vectorsCachePath)) {\n      const dump = await fse.readJSON(_vectorsCachePath)\n      if (dump) {\n        const kve = dump.map(x => ({ e: x.e, k: x.k, v: Float32Array.from(Object.values(x.v)) }))\n        _vectorsCache.load(kve)\n      }\n    }\n  } catch (err) {\n    debug('could not restore vectors cache, error: %s', err.message)\n  }\n}\n\nconst restoreCachePromise = restoreVectorsCache()\n\nconst ENDPOINT = process.env.BP_MODULE_KB_ENDPOINT || 'https://covid-qc-qna.botpress.cloud'\nconst getCacheKey = (lang: string, input: string) =>\n  `${hash(sanitizeText(input))\n    .toLowerCase()\n    .trim()}//${lang.toLowerCase().trim()}`\n\nexport default class RemoteModel implements Model {\n  private training = false\n  private cancelled = false\n\n  constructor(\n    private entries: Entry[] = [],\n    private langs: string[] = [],\n    private trained: boolean = false,\n    private model?: TrainedModel\n  ) {}\n\n  private async getPhraseVector(phrase: string, lang: string): Promise<number[] | undefined> {\n    try {\n      const cacheKey = getCacheKey(lang, phrase)\n\n      if (_vectorsCache.has(cacheKey)) {\n        return Array.from(_vectorsCache.get(cacheKey).values())\n      }\n\n      const { data } = await axios.post(ENDPOINT + '/embeddings', {\n        lang: lang.toLowerCase().trim(),\n        documents: [sanitizeText(phrase)]\n      })\n      // console.log(data)\n      // console.log(data.data)\n\n      const embeddings = data.data[0]\n      if (!embeddings || !embeddings.length || isNaN(embeddings[0])) {\n        throw new Error('Received invalid embeddings')\n      }\n\n      _vectorsCache.set(getCacheKey(lang, phrase), embeddings)\n      onVectorsCacheChanged() // TODO:\n      return embeddings\n    } catch (err) {\n      console.log(err)\n    }\n  }\n\n  async train(data: Entry[]): Promise<boolean> {\n    if (this.training) {\n      throw new Error('Already training')\n    }\n\n    if (this.trained) {\n      throw new Error('Already trained')\n    }\n\n    await restoreCachePromise // TODO:\n\n    this.trained = false\n    this.cancelled = false\n    this.training = true\n\n    try {\n      const langs = _.uniq(_.flatten(data.map(x => [...Object.keys(x.content), ...Object.keys(x.title)])))\n      const { progress } = (function() {\n        let i = 0\n        const total = data.length\n        const progress = () => {\n          const percent = ((i++ / total) * 100).toFixed(1)\n          debug(`Progress is ${i} / ${total} (${percent} %)`)\n        }\n        return { progress }\n      })()\n\n      const model: TrainedModel = { entries: [...data], support_vectors: [], trained_on: new Date() }\n\n      for (const entry of data) {\n        if (this.cancelled) {\n          break\n        }\n        for (const lang of langs) {\n          if (this.cancelled) {\n            break\n          }\n\n          const questions = _.uniq([\n            entry.title[lang],\n            ...entry.feedback[lang].filter(x => x.polarity).map(x => x.utterance)\n          ])\n\n          // TODO use every content here instead of only the 1st one\n          const title = entry.title[lang]\n          const title_embedding = await this.getPhraseVector(title, lang)\n\n          for (const content of entry.content[lang]) {\n            const originalContentEmb = await this.getPhraseVector(content, lang)\n            if (!originalContentEmb) {\n              continue\n            }\n            let reranked_emb = [...originalContentEmb]\n            for (const question of questions) {\n              const questionEmb = await this.getPhraseVector(question, lang)\n              if (!questionEmb) {\n                continue\n              }\n              const questionEmbNorm = multiply(norm(reranked_emb) / norm(questionEmb), [...questionEmb])\n              const direction = subtract(questionEmbNorm, reranked_emb)\n              reranked_emb = add(reranked_emb, multiply(0.1, direction))\n              _vectorsCache.set(getCacheKey(lang, content), Float32Array.from(reranked_emb))\n            }\n\n            // note that we do this after the for loop so we can use the latest version of mutedEmb (yes, we edit in place ...)\n            model.support_vectors.push({\n              content_embedding: reranked_emb,\n              title_embedding,\n              lang,\n              content,\n              title\n            })\n            //\n            //\n            //\n            // model.support_vectors.push({\n            //   vector: questionEmb,\n            //   lang: lang,\n            //   content: entry.content[lang][0],\n            //   entry_id: entry.id\n            // })\n          }\n        }\n\n        progress()\n      }\n\n      if (!this.cancelled) {\n        this.entries = data\n        this.langs = langs\n        this.trained = true\n        this.model = model\n      }\n    } catch (err) {\n      this.trained = false\n      debug('Error training KB', err)\n    } finally {\n      this.training = false\n      this.cancelled = false\n      return this.trained\n    }\n  }\n\n  cancelTraining(): void {\n    if (!this.training) {\n      throw new Error(\"Can't cancel training because training has not started\")\n    }\n\n    this.cancelled = true\n  }\n\n  // async predict(input: string, langCode: string): Promise<Prediction[]> {\n  //   if (!this.trained) {\n  //     throw new Error(\"Can't predict because model is not trained\")\n  //   }\n\n  //   if (this.training) {\n  //     throw new Error(\"Can't predict because model is currently training\")\n  //   }\n\n  //   langCode = langCode.toLowerCase().trim()\n  //   input = sanitizeText(input)\n\n  //   // get input embeddings\n\n  //   const {\n  //     data: { embeddings }\n  //   } = await axios.post(ENDPOINT + '/embeddings', {\n  //     lang: langCode,\n  //     text: input\n  //   })\n\n  //   const results = _.chain(this.entries)\n  //     .filter(e => !!e.title[langCode])\n  //     .map(entry => {\n  //       const dist = (a, b) => (similarity.cosine(a, b) * (4 - Math.min(distance.euclidean(a, b), 4))) / 4\n  //       const titleEmb = this.cache[getCacheKey(langCode, entry.title[langCode])]\n  //       const content = (entry.content[langCode] || [])\n  //         .map((x, i) => ({\n  //           index: i,\n  //           content: x,\n  //           embedding: this.cache[getCacheKey(langCode, x)],\n  //           confidence: 0\n  //         }))\n  //         .filter(x => !!x.embedding && x.content && x.content.length >= 20)\n  //         .map(c => ({\n  //           ...c,\n  //           confidence: dist(c.embedding, embeddings)\n  //         }))\n\n  //       const titleDist = titleEmb ? dist(embeddings, titleEmb) : 0\n\n  //       const confidences = [titleDist]\n\n  //       const topContent = _.maxBy(content, 'confidence')\n  //       if (topContent?.confidence > 0) {\n  //         // confidences.push(topContent.confidence)\n  //       }\n\n  //       return {\n  //         ...entry,\n  //         confidence: _.mean(confidences),\n  //         content: entry.content[langCode] && entry.content[langCode].join(' ')\n  //       }\n  //     })\n  //     .filter(x => !isNaN(x.confidence) && x.confidence > 0)\n  //     .orderBy('confidence', 'desc')\n  //     .take(3)\n  //     .value()\n\n  //   try {\n  //     const {\n  //       data: { answers }\n  //     } = await axios.post(ENDPOINT + '/answers', {\n  //       lang: langCode.toLowerCase().trim(),\n  //       question: sanitizeText(input),\n  //       docs: results.map(result => result.content)\n  //     })\n\n  //     return _.orderBy(\n  //       results.map((r, i) => ({\n  //         title: r.title[langCode],\n  //         content: r.content,\n  //         confidence: r.confidence,\n  //         entry_id: r.id,\n  //         highlight_start: answers[i].start,\n  //         highlight_end: answers[i].end,\n  //         answer: r.content.substr(answers[i].start, answers[i].end),\n  //         answerSnippet: r.content.substr(\n  //           Math.max(0, r.content.lastIndexOf('.', answers[i].start)),\n  //           r.content.indexOf('.', answers[i].start) > 0 ? r.content.indexOf('.', answers[i].start) : undefined\n  //         )\n  //       })),\n  //       'confidence',\n  //       'desc'\n  //     )\n  //   } catch (err) {\n  //     console.log(err)\n  //   }\n\n  //   return results.map((r, i) => ({\n  //     title: r.title[langCode],\n  //     content: r.content,\n  //     confidence: r.confidence,\n  //     entry_id: r.id,\n  //     highlight_start: -1,\n  //     highlight_end: -1,\n  //     answer: null,\n  //     answerSnippet: null\n  //   }))\n  // }\n\n  compute_confidence(support_vectors: SupportVector, question_embed) {\n    const conf_content = similarity.cosine(support_vectors.content_embedding, question_embed)\n    const conf_title = similarity.cosine(support_vectors.title_embedding, question_embed)\n    const confidence = (conf_title + conf_content) / 2\n\n    // TODO : timestamp should affect confidence\n\n    // timestamps = np.array([sub_dic[\"ts\"] for sub_dic in dico.values()])\n    // min_ts = np.min(timestamps)\n    // max_ts = np.max(timestamps)\n    // trunc_ts = np.floor(min_ts / max_ts * 100\n    // score_ts = 1 / (1 + exp((timestamp / max_ts * 100) - trunc_ts))\n    //     weight_cos = WEIGHT_CONTENT\n    //     pertinance = (weight_cos * score_cos + score_ts) / (weight_cos + 1)\n    return confidence\n  }\n\n  async predict(input: string, langCode: string): Promise<any> {\n    if (!this.trained) {\n      throw new Error(\"Can't predict because model is not trained\")\n    }\n\n    if (this.training) {\n      throw new Error(\"Can't predict because model is currently training\")\n    }\n\n    langCode = langCode.toLowerCase().trim()\n\n    const question_embed = await this.getPhraseVector(input, langCode)\n\n    const sv = this.model.support_vectors\n      .filter(x => x.lang === langCode)\n      .map(sv => ({\n        ...sv,\n        confidence: this.compute_confidence(sv, question_embed)\n      }))\n\n    const top: any[] = _.chain(sv)\n      .filter(x => !isNaN(x.confidence) && x.confidence > 0)\n      .orderBy('confidence', 'desc')\n      .take(3)\n      .value()\n\n    // const paylaod = {\n    //   lang: langCode.toLowerCase().trim(),\n    //   question: sanitizeText(input),\n    //   // documents: _.flatMap(top, res => [res.content, res.title])\n    //   documents: [top[0].content, top[0].title]\n    // }\n    // const { data } = await axios.post(ENDPOINT + '/answers', paylaod)\n\n    return {\n      docs: [\n        { content: top[0].content, score: top[0].confidence },\n        { content: top[1].content, score: top[1].confidence },\n        { content: top[2].content, score: top[2].confidence }\n      ]\n      // answer: { content: data.answer, score: data.score }\n    }\n    // return _.orderBy(\n    //   results.map((r, i) => ({\n    //     title: r.title[langCode],\n    //     content: r.content,\n    //     confidence: r.confidence,\n    //     entry_id: r.id,\n    //     highlight_start: answers[i].start,\n    //     highlight_end: answers[i].end,\n    //     answer: r.content.substr(answers[i].start, answers[i].end),\n    //     answerSnippet: r.content.substr(\n    //       Math.max(0, r.content.lastIndexOf('.', answers[i].start)),\n    //       r.content.indexOf('.', answers[i].start) > 0 ? r.content.indexOf('.', answers[i].start) : undefined\n    //     )\n    //   })),\n    //   'confidence',\n    //   'desc'\n    // )\n  }\n\n  toJSON(): string {\n    if (!this.trained) {\n      throw new Error(\"Can't serialize model because model is not trained\")\n    }\n\n    if (this.training) {\n      throw new Error(\"Can't serialize model because model is currently training\")\n    }\n\n    return JSON.stringify({\n      trained: this.trained,\n      entries: this.entries,\n      model: this.model,\n      langs: this.langs\n    })\n  }\n\n  static async fromJSON(data: string): Promise<RemoteModel> {\n    const { model, langs, entries, trained } = JSON.parse(data)\n    return new RemoteModel(entries, langs, trained, model)\n  }\n}\n"]}